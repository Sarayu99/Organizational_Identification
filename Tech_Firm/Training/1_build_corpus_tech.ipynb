{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffa9057a-fcda-487b-96c6-d5349950bc22",
   "metadata": {},
   "source": [
    "**Company** : Tech Firm\n",
    "\n",
    "**Notebook Function** :\n",
    "    This notebook builds the Tech firm data that can be passed to Glove to train company embeddings from scratch.\n",
    "\n",
    "**Input File(s)** : \n",
    "    tech_email_data.zip - The zipped folder containing the Tech firm data\n",
    "    lid.176.ftz - Model for language identification\n",
    "\n",
    "**Output File(s)** :\n",
    "    corpus_high_prob_eng0.8_tech.txt - Tech firm corpus\n",
    "\n",
    "**Author(s)** : Lara Yang, Sarayu Anshuman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76675ab-8583-4a12-800d-ba701a56b2d0",
   "metadata": {},
   "source": [
    "Unzip the processed email data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb0bd6b-58c2-4eea-aaa3-e679a6d98677",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ujson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeba639-2df0-4d77-ab3b-fe0ae5bbef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0301dc-dcaa-4ca8-98e5-511631300543",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6bdeeb-6e7b-492e-81a8-beeb4b63a256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dedb67-e133-4b89-bccf-90d393040b92",
   "metadata": {},
   "source": [
    "unzip the file. The zipped file is 1 GB, the unzipped file is 132 GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b03e9a-8a74-4f40-b925-fd419f6053e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "current_dir = os.getcwd()\n",
    "with zipfile.ZipFile(\"tech_email_data.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(current_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111b825a-4fe7-48c9-a6a2-82cfe24d7e1f",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1da882c-decb-415c-af27-15d2f4e261e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import ujson as json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from utils import *\n",
    "import multiprocessing\n",
    "import fasttext\n",
    "model = fasttext.load_model('lid.176.ftz') #model to identify a language in a piece of text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfa364d-8d31-420a-9426-9689810c74b5",
   "metadata": {},
   "source": [
    "Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e680342e-a3e7-4b72-a191-9b721ff82d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "mittens_params = 0.1\n",
    "# moving this larger moves out of the default window we have seen in papers (1-10)\n",
    "# 5 was originally used in 2yp; if unspecified, 10 is the default\n",
    "window_size = 10\n",
    "# seems like smallest embedding dim works best given that there might not that many dimensions needed to capture the difference between i and we\n",
    "# 100 was originally used in 2yp; if unspecified, 50 is the default\n",
    "embedding_dim = 50\n",
    "mincount = 150\n",
    "max_iter = 100\n",
    "num_cores = 10\n",
    "num_users_to_test = 60\n",
    "vocab_size = 2500\n",
    "max_iter_all = 3000\n",
    "ling_thres = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da46b19-67cc-4bc1-9bd4-11572a91fe31",
   "metadata": {},
   "source": [
    "Set output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3215ae-a93f-45f2-b91c-a831d4b300f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = current_dir\n",
    "corpus_dir = os.path.join(home_dir, \"cleaned_email_data_v2\")\n",
    "print(corpus_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70a2002-456f-4e8b-8d85-aa493b344edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = current_dir\n",
    "corpus_file = os.path.join(out_dir, 'corpus_high_prob_eng_{}_tech.txt'.format(str(ling_thres).replace(\".\", \"\")))\n",
    "print(corpus_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38f8f8e-e103-4ae7-83e6-cdd31fb990be",
   "metadata": {},
   "source": [
    "Generate the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27439351-ec41-4378-934e-edc822449ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_emails = 0\n",
    "non_english = 0\n",
    "english = 0\n",
    "ling_thres = 0.8 #setting same value for Staffing firm\n",
    "\n",
    "def load_user_emails(corpus_dir, out_file):\n",
    "    output_file = open(out_file, 'w')\n",
    "    uid2emails = defaultdict(list)\n",
    "    print('reached here')\n",
    "    for filename in os.listdir(corpus_dir):\n",
    "        usr = filename.replace('.txt', '') #extarct the user number\n",
    "        with open(os.path.join(corpus_dir, filename), encoding='utf-8') as f:\n",
    "            global total_emails, english, non_english\n",
    "            emails = json.load(f) #load each individual user's emails\n",
    "            uid2emails[usr] = emails #create a dictionary where the key is the user number, and all the user's emails is the values\n",
    "            eng_emails = []\n",
    "            for e in emails:\n",
    "                 total_emails += 1\n",
    "                 clean_e = ' '.join(e['body'].split('\\n')) #obtain the entire email sentences as one piece of text, note that '\\n' referes to a space in tech firm\n",
    "                 if len(clean_e) == 0:\n",
    "                     continue\n",
    "                 r = model.predict(clean_e)\n",
    "                 lang = (r[0][0], r[1][0])\n",
    "                 if lang[0] == '__label__en' and lang[1] > ling_thres:\n",
    "                     eng_emails.append(e)\n",
    "                     output_file.write(clean_e + ' \\n ')\n",
    "                     english += 1\n",
    "                 else:\n",
    "                     non_english\n",
    "            uid2emails[usr] = eng_emails\n",
    "    output_file.close()\n",
    "    return uid2emails\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    load_user_emails(corpus_dir, corpus_file)\n",
    "    print(\"\"\"Out of {} emails processed, {} emails were non_empty.\\n\n",
    "        {} English emails were written to corpus.txt. {} emails non-English emails are discarded.\"\"\".format(total_emails, english+non_english, english, non_english))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2869053d-c4b1-4e70-953d-3bda6e95693f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
